{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from dvalib import yolo\n",
    "import argparse\n",
    "import colorsys\n",
    "import imghdr\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "from keras import backend as K\n",
    "from keras.models import load_model\n",
    "from PIL import Image\n",
    "from dvalib.yolo.yad2k.models.keras_yolo import yolo_eval, yolo_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "path = '/Users/aub3/Dropbox/DeepVideoAnalytics/dvalib/yolo/'\n",
    "args = {\n",
    "    'model_path':'{}/model_data/yolo.h5'.format(path),\n",
    "    'anchors_path': '{}/model_data/yolo_anchors.txt'.format(path),\n",
    "    'classes_path': '{}/model_data/coco_classes.txt'.format(path),\n",
    "    'test_path': '{}/images'.format(path),\n",
    "    'output_path': '{}/images/out'.format(path),\n",
    "    'score_threshold': 0.3,\n",
    "    'iou_threshold': 0.5,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/aub3/Dropbox/DeepVideoAnalytics/dvalib/yolo//model_data/yolo.h5 model, anchors, and classes loaded.\n"
     ]
    }
   ],
   "source": [
    "model_path = os.path.expanduser(args['model_path'])\n",
    "anchors_path = os.path.expanduser(args['anchors_path'])\n",
    "classes_path = os.path.expanduser(args['classes_path'])\n",
    "test_path = os.path.expanduser(args['test_path'])\n",
    "output_path = os.path.expanduser(args['output_path'])\n",
    "if not os.path.exists(output_path):\n",
    "    print('Creating output path {}'.format(output_path))\n",
    "    os.mkdir(output_path)\n",
    "sess = K.get_session()\n",
    "with open(classes_path) as f:\n",
    "    class_names = f.readlines()\n",
    "class_names = [c.strip() for c in class_names]\n",
    "with open(anchors_path) as f:\n",
    "    anchors = f.readline()\n",
    "    anchors = [float(x) for x in anchors.split(',')]\n",
    "    anchors = np.array(anchors).reshape(-1, 2)\n",
    "yolo_model = load_model(model_path)\n",
    "num_classes = len(class_names)\n",
    "num_anchors = len(anchors)\n",
    "# TODO: Assumes dim ordering is channel last\n",
    "model_output_channels = yolo_model.layers[-1].output_shape[-1]\n",
    "assert model_output_channels == num_anchors * (num_classes + 5), \\\n",
    "    'Mismatch between model and given anchor and class sizes. ' \\\n",
    "    'Specify matching anchors and classes with --anchors_path and ' \\\n",
    "    '--classes_path flags.'\n",
    "print('{} model, anchors, and classes loaded.'.format(model_path))\n",
    "\n",
    "# Check if model is fully convolutional, assuming channel last order.\n",
    "model_image_size = yolo_model.layers[0].input_shape[1:3]\n",
    "is_fixed_size = model_image_size != (None, None)\n",
    "hsv_tuples = [(x / len(class_names), 1., 1.)for x in range(len(class_names))]\n",
    "colors = list(map(lambda x: colorsys.hsv_to_rgb(*x), hsv_tuples))\n",
    "colors = list(map(lambda x: (int(x[0] * 255), int(x[1] * 255), int(x[2] * 255)),colors))\n",
    "random.seed(10101)  # Fixed seed for consistent colors across runs.\n",
    "random.shuffle(colors)  # Shuffle colors to decorrelate adjacent classes.\n",
    "random.seed(None)  # Reset seed to default.\n",
    "yolo_outputs = yolo_head(yolo_model.output, anchors, len(class_names))\n",
    "input_image_shape = K.placeholder(shape=(2, ))\n",
    "boxes, scores, classes = yolo_eval(yolo_outputs,input_image_shape,score_threshold=args['score_threshold'],iou_threshold=args['iou_threshold'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3 boxes for dog.jpg\n",
      "('truck 0.79', (441, 80), (703, 171))\n",
      "('dog 0.79', (123, 222), (327, 528))\n",
      "('bicycle 0.83', (128, 127), (570, 435))\n",
      "Found 1 boxes for eagle.jpg\n",
      "('bird 0.90', (144, 89), (618, 445))\n",
      "Found 2 boxes for giraffe.jpg\n",
      "('zebra 0.80', (290, 199), (430, 451))\n",
      "('giraffe 0.88', (172, 31), (452, 420))\n",
      "Found 5 boxes for horses.jpg\n",
      "('horse 0.42', (98, 176), (463, 349))\n",
      "('horse 0.69', (237, 201), (426, 370))\n",
      "('horse 0.71', (0, 197), (153, 384))\n",
      "('horse 0.83', (436, 211), (603, 348))\n",
      "('horse 0.90', (0, 191), (335, 414))\n",
      "Found 3 boxes for person.jpg\n",
      "('dog 0.82', (61, 264), (200, 351))\n",
      "('horse 0.86', (404, 133), (602, 344))\n",
      "('person 0.87', (190, 94), (276, 380))\n",
      "Found 0 boxes for scream.jpg\n"
     ]
    }
   ],
   "source": [
    "for image_file in os.listdir(test_path):\n",
    "    try:\n",
    "        image_type = imghdr.what(os.path.join(test_path, image_file))\n",
    "        if not image_type:\n",
    "            continue\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "    image = Image.open(os.path.join(test_path, image_file))\n",
    "    if is_fixed_size:  # TODO: When resizing we can use minibatch input.\n",
    "        resized_image = image.resize(\n",
    "            tuple(reversed(model_image_size)), Image.BICUBIC)\n",
    "        image_data = np.array(resized_image, dtype='float32')\n",
    "    else:\n",
    "        # Due to skip connection + max pooling in YOLO_v2, inputs must have\n",
    "        # width and height as multiples of 32.\n",
    "        new_image_size = (image.width - (image.width % 32),\n",
    "                          image.height - (image.height % 32))\n",
    "        resized_image = image.resize(new_image_size, Image.BICUBIC)\n",
    "        image_data = np.array(resized_image, dtype='float32')\n",
    "        print(image_data.shape)\n",
    "    image_data /= 255.\n",
    "    image_data = np.expand_dims(image_data, 0)  # Add batch dimension.\n",
    "    out_boxes, out_scores, out_classes = sess.run([boxes, scores, classes],feed_dict={yolo_model.input: image_data,input_image_shape: [image.size[1], image.size[0]],K.learning_phase(): 0})\n",
    "    print('Found {} boxes for {}'.format(len(out_boxes), image_file))\n",
    "    thickness = (image.size[0] + image.size[1]) // 300\n",
    "    for i, c in reversed(list(enumerate(out_classes))):\n",
    "        predicted_class = class_names[c]\n",
    "        box = out_boxes[i]\n",
    "        score = out_scores[i]\n",
    "        label = '{} {:.2f}'.format(predicted_class, score)\n",
    "        top, left, bottom, right = box\n",
    "        top = max(0, np.floor(top + 0.5).astype('int32'))\n",
    "        left = max(0, np.floor(left + 0.5).astype('int32'))\n",
    "        bottom = min(image.size[1], np.floor(bottom + 0.5).astype('int32'))\n",
    "        right = min(image.size[0], np.floor(right + 0.5).astype('int32'))\n",
    "        print(label, (left, top), (right, bottom))\n",
    "    image.save(os.path.join(output_path, image_file), quality=90)\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
