{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from dvalib import yolo\n",
    "import random,glob,os\n",
    "import numpy as np\n",
    "from keras import backend as K\n",
    "from keras.models import load_model\n",
    "from PIL import Image\n",
    "from dvalib.yolo.keras_yolo import yolo_eval, yolo_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "path = '/Users/aub3/Dropbox/DeepVideoAnalytics/dvalib/yolo/'\n",
    "args = {\n",
    "    'model_path':'{}/model_data/yolo.h5'.format(path),\n",
    "    'anchors_path': '{}/model_data/yolo_anchors.txt'.format(path),\n",
    "    'classes_path': '{}/model_data/coco_classes.txt'.format(path),\n",
    "    'test_path': '{}/images'.format(path),\n",
    "    'output_path': '{}/images/out'.format(path),\n",
    "    'score_threshold': 0.3,\n",
    "    'iou_threshold': 0.5,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_path = os.path.expanduser(args['model_path'])\n",
    "anchors_path = os.path.expanduser(args['anchors_path'])\n",
    "classes_path = os.path.expanduser(args['classes_path'])\n",
    "test_path = os.path.expanduser(args['test_path'])\n",
    "output_path = os.path.expanduser(args['output_path'])\n",
    "sess = K.get_session()\n",
    "class_names = [c.strip() for c in file(classes_path)]\n",
    "anchors = np.array( [float(x) for x in file(anchors_path).read().split(',') if x.strip()]).reshape(-1, 2)\n",
    "yolo_model = load_model(model_path)\n",
    "num_classes,num_anchors = len(class_names), len(anchors)\n",
    "model_output_channels = yolo_model.layers[-1].output_shape[-1]\n",
    "assert model_output_channels == num_anchors * (num_classes + 5)\n",
    "model_image_size = yolo_model.layers[0].input_shape[1:3]\n",
    "is_fixed_size = model_image_size != (None, None)\n",
    "hsv_tuples = [(x / len(class_names), 1., 1.)for x in range(len(class_names))]\n",
    "yolo_outputs = yolo_head(yolo_model.output, anchors, len(class_names))\n",
    "input_image_shape = K.placeholder(shape=(2, ))\n",
    "boxes, scores, classes = yolo_eval(yolo_outputs,input_image_shape,score_threshold=args['score_threshold'],iou_threshold=args['iou_threshold'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for image_file in glob.glob(test_path+\"/*.jpg\"):\n",
    "    image = Image.open(os.path.join(test_path, image_file))\n",
    "    if is_fixed_size:  # TODO: When resizing we can use minibatch input.\n",
    "        resized_image = image.resize(\n",
    "            tuple(reversed(model_image_size)), Image.BICUBIC)\n",
    "        image_data = np.array(resized_image, dtype='float32')\n",
    "    else:\n",
    "        new_image_size = (image.width - (image.width % 32),image.height - (image.height % 32))\n",
    "        resized_image = image.resize(new_image_size, Image.BICUBIC)\n",
    "        image_data = np.array(resized_image, dtype='float32')\n",
    "        print(image_data.shape)\n",
    "    image_data /= 255.\n",
    "    image_data = np.expand_dims(image_data, 0)  # Add batch dimension.\n",
    "    out_boxes, out_scores, out_classes = sess.run([boxes, scores, classes],feed_dict={yolo_model.input: image_data,input_image_shape: [image.size[1], image.size[0]],K.learning_phase(): 0})\n",
    "    for i, c in reversed(list(enumerate(out_classes))):\n",
    "        predicted_class = class_names[c]\n",
    "        box = out_boxes[i]\n",
    "        score = out_scores[i]\n",
    "        label = '{} {:.2f}'.format(predicted_class, score)\n",
    "        top, left, bottom, right = box\n",
    "        top = max(0, np.floor(top + 0.5).astype('int32'))\n",
    "        left = max(0, np.floor(left + 0.5).astype('int32'))\n",
    "        bottom = min(image.size[1], np.floor(bottom + 0.5).astype('int32'))\n",
    "        right = min(image.size[0], np.floor(right + 0.5).astype('int32'))\n",
    "        print(label, (left, top), (right, bottom))\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
