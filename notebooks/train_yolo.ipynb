{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys,os\n",
    "sys.path.append('../')\n",
    "# os.environ['LD_LIBRARY_PATH']='/home/aub3/Desktop/cuda/lib64/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "# import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import PIL\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "from keras.layers import Input, Lambda, Conv2D\n",
    "from keras.models import load_model, Model\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint, EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from dvalib.yolo.keras_yolo import preprocess_true_boxes, yolo_body,yolo_eval, yolo_head, yolo_loss\n",
    "anchors_path = \"model_data/yolo_anchors.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = np.load('/home/aub3/Desktop/underwater_data.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "YOLO_ANCHORS = np.array(((0.57273, 0.677385), (1.87446, 2.06253), (3.33843, 5.47434),(7.88282, 3.52778), (9.77052, 9.16828)))\n",
    "class_names = [\"red_buoy\",\"green_buoy\",\"yellow_buoy\",\"path_marker\",\"start_gate\",\"channel\"]\n",
    "# anchors = np.array([float(x) for x in file(anchors_path).readline().split(',')]).reshape(-1, 2)\n",
    "anchors = YOLO_ANCHORS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_detector_mask(boxes, anchors):\n",
    "    '''\n",
    "    Precompute detectors_mask and matching_true_boxes for training.\n",
    "    Detectors mask is 1 for each spatial position in the final conv layer and\n",
    "    anchor that should be active for the given boxes and 0 otherwise.\n",
    "    Matching true boxes gives the regression targets for the ground truth box\n",
    "    that caused a detector to be active or 0 otherwise.\n",
    "    '''\n",
    "    detectors_mask = [0 for i in range(len(boxes))]\n",
    "    matching_true_boxes = [0 for i in range(len(boxes))]\n",
    "    for i, box in enumerate(boxes):\n",
    "        detectors_mask[i], matching_true_boxes[i] = preprocess_true_boxes(box, anchors, [416, 416])\n",
    "\n",
    "    return np.array(detectors_mask), np.array(matching_true_boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_data(images, boxes):\n",
    "    images = [PIL.Image.fromarray(i) for i in images]\n",
    "    orig_size = np.array([float(images[0].width), float(images[0].height)])\n",
    "    orig_size = np.expand_dims(orig_size, axis=0)\n",
    "    print orig_size\n",
    "    processed_images = [i.resize((416, 416), PIL.Image.BICUBIC) for i in images]\n",
    "    processed_images = [np.array(image, dtype=np.float) for image in processed_images]\n",
    "    processed_images = [image/255. for image in processed_images]\n",
    "    boxes = [box.reshape((-1, 5)) for box in boxes]\n",
    "    boxes_extents = [box[:, [2, 1, 4, 3, 0]] for box in boxes]\n",
    "    boxes_xy = [0.5 * (box[:, 3:5] + box[:, 1:3]) for box in boxes]\n",
    "    boxes_wh = [box[:, 3:5] - box[:, 1:3] for box in boxes]\n",
    "    print boxes_wh[0]\n",
    "    boxes_xy = [boxxy / orig_size for boxxy in boxes_xy]\n",
    "    boxes_wh = [boxwh / orig_size for boxwh in boxes_wh]\n",
    "    print \"width,height\",boxes_wh[0]\n",
    "    boxes = [np.concatenate((boxes_xy[i], boxes_wh[i], box[:, 0:1]), axis=1) for i, box in enumerate(boxes)]\n",
    "    max_boxes = 0\n",
    "    for boxz in boxes:\n",
    "        if boxz.shape[0] > max_boxes:\n",
    "            max_boxes = boxz.shape[0]\n",
    "    print \"max_boxes\",max_boxes\n",
    "    for i, boxz in enumerate(boxes):\n",
    "        if boxz.shape[0]  < max_boxes:\n",
    "            zero_padding = np.zeros( (max_boxes-boxz.shape[0], 5), dtype=np.float32)\n",
    "            boxes[i] = np.vstack((boxz, zero_padding))\n",
    "    return np.array(processed_images), np.array(boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print len(data['images'])\n",
    "print data['boxes'][10]\n",
    "image_data, boxes = process_data(data['images'][:1000], data['boxes'][:1000])\n",
    "print len(image_data),len(boxes)\n",
    "print boxes[10].shape\n",
    "print boxes[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "detectors_mask, matching_true_boxes = get_detector_mask(boxes, anchors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "detectors_mask[10].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print detectors_mask.shape\n",
    "print matching_true_boxes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_model(anchors, class_names, load_pretrained=True, freeze_body=True):\n",
    "    '''\n",
    "    returns the body of the model and the model\n",
    "    load_pretrained: whether or not to load the pretrained model or initialize all weights\n",
    "    freeze_body: whether or not to freeze all weights except for the last layer's\n",
    "    model_body: YOLOv2 with new output layer\n",
    "    model: YOLOv2 with custom loss Lambda layer\n",
    "    '''\n",
    "    detectors_mask_shape = (13, 13, 5, 1)\n",
    "    matching_boxes_shape = (13, 13, 5, 5)\n",
    "\n",
    "    # Create model input layers.\n",
    "    image_input = Input(shape=(416, 416, 3))\n",
    "    boxes_input = Input(shape=(None, 5))\n",
    "    detectors_mask_input = Input(shape=detectors_mask_shape)\n",
    "    matching_boxes_input = Input(shape=matching_boxes_shape)\n",
    "\n",
    "    # Create model body.\n",
    "    yolo_model = yolo_body(image_input, len(anchors), len(class_names))\n",
    "    topless_yolo = Model(yolo_model.input, yolo_model.layers[-2].output)\n",
    "\n",
    "    if load_pretrained:\n",
    "        # Save topless yolo:\n",
    "        topless_yolo_path = os.path.join('/home/aub3/repos/DeepVideoAnalytics/dvalib/yolo/model_data/', 'yolo_topless.h5')\n",
    "        if not os.path.exists(topless_yolo_path):\n",
    "            print(\"CREATING TOPLESS WEIGHTS FILE\")\n",
    "            yolo_path = '/home/aub3/repos/DeepVideoAnalytics/dvalib/yolo/model_data/yolo.h5'\n",
    "            model_body = load_model(yolo_path)\n",
    "            model_body = Model(model_body.inputs, model_body.layers[-2].output)\n",
    "            model_body.save_weights(topless_yolo_path)\n",
    "        topless_yolo.load_weights(topless_yolo_path)\n",
    "\n",
    "    if freeze_body:\n",
    "        for layer in topless_yolo.layers:\n",
    "            layer.trainable = False\n",
    "    final_layer = Conv2D(len(anchors)*(5+len(class_names)), (1, 1), activation='linear')(topless_yolo.output)\n",
    "\n",
    "    model_body = Model(image_input, final_layer)\n",
    "\n",
    "    # Place model loss on CPU to reduce GPU memory usage.\n",
    "    with tf.device('/cpu:0'):\n",
    "        # TODO: Replace Lambda with custom Keras layer for loss.\n",
    "        model_loss = Lambda(\n",
    "            yolo_loss,\n",
    "            output_shape=(1, ),\n",
    "            name='yolo_loss',\n",
    "            arguments={'anchors': anchors,\n",
    "                       'num_classes': len(class_names)})([\n",
    "                           model_body.output, boxes_input,\n",
    "                           detectors_mask_input, matching_boxes_input\n",
    "                       ])\n",
    "\n",
    "    model = Model(\n",
    "        [model_body.input, boxes_input, detectors_mask_input,\n",
    "         matching_boxes_input], model_loss)\n",
    "\n",
    "    return model_body, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_body, model = create_model(anchors, class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(model, class_names, anchors, image_data, boxes, detectors_mask, matching_true_boxes, validation_split=0.1):\n",
    "    '''\n",
    "    retrain/fine-tune the model\n",
    "\n",
    "    logs training with tensorboard\n",
    "\n",
    "    saves training weights in current directory\n",
    "\n",
    "    best weights according to val_loss is saved as trained_stage_3_best.h5\n",
    "    '''\n",
    "    model.compile(\n",
    "        optimizer='adam', loss={\n",
    "            'yolo_loss': lambda y_true, y_pred: y_pred\n",
    "        })  # This is a hack to use the custom loss function in the last layer.\n",
    "\n",
    "\n",
    "    logging = TensorBoard()\n",
    "    checkpoint = ModelCheckpoint(\"trained_stage_3_best.h5\", monitor='val_loss',\n",
    "                                 save_weights_only=True, save_best_only=True)\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', min_delta=0, patience=15, verbose=1, mode='auto')\n",
    "\n",
    "    model.fit([image_data, boxes, detectors_mask, matching_true_boxes],\n",
    "              np.zeros(len(image_data)),\n",
    "              validation_split=validation_split,\n",
    "              batch_size=32,\n",
    "              epochs=20,\n",
    "              callbacks=[logging,checkpoint, early_stopping])\n",
    "    model.save_weights('trained_stage_1.h5')\n",
    "\n",
    "    model_body, model = create_model(anchors, class_names, load_pretrained=False, freeze_body=False)\n",
    "\n",
    "    model.load_weights('trained_stage_1.h5')\n",
    "\n",
    "    model.compile(\n",
    "        optimizer='adam', loss={\n",
    "            'yolo_loss': lambda y_true, y_pred: y_pred\n",
    "        })  # This is a hack to use the custom loss function in the last layer.\n",
    "\n",
    "\n",
    "#     model.fit([image_data, boxes, detectors_mask, matching_true_boxes],\n",
    "#               np.zeros(len(image_data)),\n",
    "#               validation_split=0.1,\n",
    "#               batch_size=8,\n",
    "#               epochs=10,\n",
    "#               callbacks=[logging])\n",
    "\n",
    "#     model.save_weights('trained_stage_2.h5')\n",
    "\n",
    "#     model.fit([image_data, boxes, detectors_mask, matching_true_boxes],\n",
    "#               np.zeros(len(image_data)),\n",
    "#               validation_split=0.1,\n",
    "#               batch_size=8,\n",
    "#               epochs=10,\n",
    "#               callbacks=[logging, checkpoint, early_stopping])\n",
    "\n",
    "#     model.save_weights('trained_stage_3.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train(model,class_names,anchors,image_data,boxes,detectors_mask,matching_true_boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import dvalib.yolo.draw_boxes as draw_boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reload(draw_boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def draw(model_body, class_names, anchors, image_data, image_set='val',\n",
    "            weights_name='trained_stage_3_best.h5', out_path=\"output_images\", save_all=True):\n",
    "    '''\n",
    "    Draw bounding boxes on image data\n",
    "    '''\n",
    "    if image_set == 'train':\n",
    "        image_data = np.array([np.expand_dims(image, axis=0)\n",
    "            for image in image_data[:int(len(image_data)*.9)]])\n",
    "    elif image_set == 'val':\n",
    "        image_data = np.array([np.expand_dims(image, axis=0)\n",
    "            for image in image_data[int(len(image_data)*.9):]])\n",
    "    elif image_set == 'all':\n",
    "        image_data = np.array([np.expand_dims(image, axis=0)\n",
    "            for image in image_data])\n",
    "    else:\n",
    "        ValueError(\"draw argument image_set must be 'train', 'val', or 'all'\")\n",
    "    # model.load_weights(weights_name)\n",
    "    print(image_data.shape)\n",
    "    model_body.load_weights(weights_name)\n",
    "\n",
    "    # Create output variables for prediction.\n",
    "    yolo_outputs = yolo_head(model_body.output, anchors, len(class_names))\n",
    "    input_image_shape = K.placeholder(shape=(2, ))\n",
    "    boxes, scores, classes = yolo_eval(\n",
    "        yolo_outputs, input_image_shape, score_threshold=0.5, iou_threshold=0)\n",
    "\n",
    "    # Run prediction on overfit image.\n",
    "    sess = K.get_session()  # TODO: Remove dependence on Tensorflow session.\n",
    "\n",
    "    if  not os.path.exists(out_path):\n",
    "        os.makedirs(out_path)\n",
    "    for i in range(len(image_data)):\n",
    "        out_boxes, out_scores, out_classes = sess.run(\n",
    "            [boxes, scores, classes],\n",
    "            feed_dict={\n",
    "                model_body.input: image_data[i],\n",
    "                input_image_shape: [image_data.shape[2], image_data.shape[3]],\n",
    "                K.learning_phase(): 0\n",
    "            })\n",
    "        print('Found {} boxes for image.'.format(len(out_boxes)))\n",
    "        print(out_boxes)\n",
    "\n",
    "        # Plot image with predicted boxes.\n",
    "        image_with_boxes = draw_boxes.draw_boxes(image_data[i][0], out_boxes, out_classes,\n",
    "                                    class_names, out_scores)\n",
    "        # Save the image:\n",
    "        if save_all or (len(out_boxes) > 0):\n",
    "            image = PIL.Image.fromarray(image_with_boxes)\n",
    "            image.save(os.path.join(out_path,str(i)+'.png'))\n",
    "        plt.imshow(image_with_boxes, interpolation='nearest')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "image_set='val' \n",
    "weights_name='trained_stage_3_best.h5'\n",
    "save_all=False\n",
    "draw(model_body,class_names,anchors,image_data,image_set=image_set,weights_name=weights_name,save_all=save_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
